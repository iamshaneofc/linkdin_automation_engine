# ============================================
# AI Provider Configuration - COPY TO backend/.env
# ============================================

# Choose your AI provider: 'openai' or 'llama'
AI_PROVIDER=llama

# === Option 1: Llama (Local / Free) ===
# Install Ollama: https://ollama.ai
# Run: ollama serve
# Download model: ollama pull llama2
LLAMA_API_URL=http://localhost:11434
LLAMA_MODEL=llama2

# Popular Llama models:
# - llama2          (7B - Fast, good quality)
# - mistral         (7B - Best balance, recommended)
# - llama2:13b      (13B - Better quality, needs 8GB+ RAM)
# - llama2:70b      (70B - Best quality, needs GPU)

# === Option 2: OpenAI (Cloud / Paid) ===
# Get API key: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-your-key-here

# ============================================
# Add these lines to your backend/.env file
# ============================================
